{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZPJxQtNvyMNJZlm4vSavn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"WMDXC0IhQJb1","executionInfo":{"status":"ok","timestamp":1768245657158,"user_tz":-300,"elapsed":315,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}}},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/"]},{"cell_type":"code","source":["import kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkhxDh6JRQJv","executionInfo":{"status":"ok","timestamp":1768245658393,"user_tz":-300,"elapsed":42,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"b6e83b65-021f-4bcf-dc3e-2faafa4dadb9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n"]}]},{"cell_type":"code","source":["!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtpcrM7oRYoX","executionInfo":{"status":"ok","timestamp":1768245744094,"user_tz":-300,"elapsed":84383,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"9678b464-8973-4212-bce8-0c83f43830f1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n","License(s): other\n","Downloading chest-xray-pneumonia.zip to /content\n","100% 2.29G/2.29G [01:08<00:00, 92.6MB/s]\n","100% 2.29G/2.29G [01:08<00:00, 35.9MB/s]\n"]}]},{"cell_type":"code","source":["import zipfile\n","zip_ref = zipfile.ZipFile(\"/content/chest-xray-pneumonia.zip\",\"r\")\n","zip_ref.extractall(\"/content/\")\n","zip_ref.close()"],"metadata":{"id":"rc9IPoveRaJP","executionInfo":{"status":"ok","timestamp":1768245775236,"user_tz":-300,"elapsed":31073,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.applications import DenseNet121, ResNet50, EfficientNetB0\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import seaborn as sns\n","import cv2\n","import os"],"metadata":{"id":"PwewnFh4RfMI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE = 224\n","BATCH_SIZE = 64\n","EPOCHS_FEATURE_EXTRACTION = 10\n","EPOCHS_FINE_TUNING = 15\n","INITIAL_LR = 1e-3\n","FINE_TUNE_LR = 1e-5\n","DRIVE_PATH = '/content/drive/MyDrive/Colab Notebooks/medicalimagefiles'\n","os.makedirs(DRIVE_PATH, exist_ok=True)\n"],"metadata":{"id":"1NWethUbSYv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_DIR = '/content/chest_xray/train'\n","VAL_DIR = '/content/chest_xray/val'\n","TEST_DIR = '/content/chest_xray/test'"],"metadata":{"id":"31jR6DiYX-bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"metadata":{"id":"wZOBnh9gYLq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_test_datagen = ImageDataGenerator(rescale=1./255)\n"],"metadata":{"id":"4i3tCgS-YSVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=True\n",")\n","val_generator = val_test_datagen.flow_from_directory(\n","    VAL_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=False\n",")\n","\n","test_generator = val_test_datagen.flow_from_directory(\n","    TEST_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrNp-qHzYURk","executionInfo":{"status":"ok","timestamp":1768075974028,"user_tz":-300,"elapsed":38,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"0c346bd3-b645-48f5-8866-e2c19b44b95a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5216 images belonging to 2 classes.\n","Found 16 images belonging to 2 classes.\n","Found 624 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["class_counts = np.bincount(train_generator.classes)\n","total = sum(class_counts)\n","class_weight = {\n","    0: total / (2 * class_counts[0]),  # NORMAL\n","    1: total / (2 * class_counts[1])   # PNEUMONIA\n","}\n","\n","print(f\"\\nClass distribution in training:\")\n","print(f\"  NORMAL: {class_counts[0]} images\")\n","print(f\"  PNEUMONIA: {class_counts[1]} images\")\n","print(f\"Class weights: {class_weight}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n01E88PiYY-_","executionInfo":{"status":"ok","timestamp":1768075974286,"user_tz":-300,"elapsed":31,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"b33992f0-cc5d-4a46-c214-880db5e21fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Class distribution in training:\n","  NORMAL: 1341 images\n","  PNEUMONIA: 3875 images\n","Class weights: {0: np.float64(1.9448173005219984), 1: np.float64(0.6730322580645162)}\n"]}]},{"cell_type":"code","source":["def build_model(base_model_builder, model_name, input_shape=(IMG_SIZE, IMG_SIZE, 3)):\n","    \"\"\"\n","    Build a transfer learning model with custom head\n","\n","    Args:\n","        base_model_builder: Function to create base model (e.g., DenseNet121)\n","        model_name: Name for the model\n","        input_shape: Input image shape\n","\n","    Returns:\n","        Compiled model\n","    \"\"\"\n","    # Load pretrained base (ImageNet weights)\n","    base_model = base_model_builder(\n","        weights='imagenet',\n","        include_top=False,\n","        input_shape=input_shape\n","    )\n","\n","    # Freeze base model for feature extraction\n","    base_model.trainable = False\n","\n","    # Build custom classifier head\n","    inputs = keras.Input(shape=input_shape)\n","    x = base_model(inputs, training=False)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dense(256, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.Dropout(0.3)(x)\n","    outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs, outputs, name=model_name)\n","\n","    return model, base_model\n"],"metadata":{"id":"9e1Jla0JYrLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, base_model, model_name):\n","    \"\"\"\n","    Two-stage training: Feature extraction then fine-tuning\n","    \"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(f\"TRAINING: {model_name}\")\n","    print(f\"{'='*60}\")\n","\n","    # ========== STAGE 1: FEATURE EXTRACTION ==========\n","    print(f\"\\nğŸ”¹ STAGE 1: Feature Extraction (base frozen)\")\n","    print(f\"Base model trainable: {base_model.trainable}\")\n","\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=INITIAL_LR),\n","        loss='binary_crossentropy',\n","        metrics=[\n","            'accuracy',\n","            keras.metrics.Precision(name='precision'),\n","            keras.metrics.Recall(name='recall'),\n","            keras.metrics.AUC(name='auc')\n","        ]\n","    )\n","\n","    callbacks_stage1 = [\n","        EarlyStopping(\n","            monitor='val_loss',\n","            patience=5,\n","            restore_best_weights=True,\n","            verbose=1\n","        ),\n","        ReduceLROnPlateau(\n","            monitor='val_loss',\n","            factor=0.5,\n","            patience=3,\n","            min_lr=1e-7,\n","            verbose=1\n","        ),\n","        ModelCheckpoint(\n","            os.path.join(DRIVE_PATH, f'{model_name}_feature_extraction.h5'), ...\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        )\n","    ]\n","\n","    history_stage1 = model.fit(\n","        train_generator,\n","        validation_data=val_generator,\n","        epochs=EPOCHS_FEATURE_EXTRACTION,\n","        class_weight=class_weight,\n","        callbacks=callbacks_stage1,\n","        verbose=1\n","    )\n","\n","    # ========== STAGE 2: FINE-TUNING ==========\n","    print(f\"\\nğŸ”¹ STAGE 2: Fine-Tuning (unfreeze top layers)\")\n","\n","    # Unfreeze the base model\n","    base_model.trainable = True\n","\n","    # Freeze all layers except the top 50\n","    total_layers = len(base_model.layers)\n","    freeze_until = total_layers - 50\n","\n","    for layer in base_model.layers[:freeze_until]:\n","        layer.trainable = False\n","\n","    trainable_count = sum([1 for layer in base_model.layers if layer.trainable])\n","    print(f\"Total layers: {total_layers}\")\n","    print(f\"Trainable layers: {trainable_count}\")\n","\n","    # Recompile with lower learning rate\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n","        loss='binary_crossentropy',\n","        metrics=[\n","            'accuracy',\n","            keras.metrics.Precision(name='precision'),\n","            keras.metrics.Recall(name='recall'),\n","            keras.metrics.AUC(name='auc')\n","        ]\n","    )\n","\n","    callbacks_stage2 = [\n","        EarlyStopping(\n","            monitor='val_loss',\n","            patience=7,\n","            restore_best_weights=True,\n","            verbose=1\n","        ),\n","        ReduceLROnPlateau(\n","            monitor='val_loss',\n","            factor=0.5,\n","            patience=3,\n","            min_lr=1e-8,\n","            verbose=1\n","        ),\n","        ModelCheckpoint(\n","            os.path.join(DRIVE_PATH, f'{model_name}_fine_tuned.h5'), ...\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        )\n","    ]\n","\n","    history_stage2 = model.fit(\n","        train_generator,\n","        validation_data=val_generator,\n","        epochs=EPOCHS_FINE_TUNING,\n","        class_weight=class_weight,\n","        callbacks=callbacks_stage2,\n","        verbose=1\n","    )\n","\n","    print(f\"\\nâœ… {model_name} training completed!\")\n","\n","    return history_stage1, history_stage2\n","\n","# ================="],"metadata":{"id":"B1ciGIGpaiuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, model_name, test_generator):\n","    \"\"\"\n","    Comprehensive evaluation with multiple metrics\n","    \"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(f\"EVALUATION: {model_name}\")\n","    print(f\"{'='*60}\")\n","\n","    # Get predictions\n","    test_generator.reset()\n","    y_pred_probs = model.predict(test_generator, verbose=1)\n","    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n","    y_true = test_generator.classes\n","\n","    # Calculate metrics\n","    test_loss, test_acc, test_precision, test_recall, test_auc = model.evaluate(\n","        test_generator, verbose=0\n","    )\n","\n","    f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-7)\n","\n","    print(f\"\\nğŸ“Š Test Metrics:\")\n","    print(f\"  Accuracy:  {test_acc:.4f}\")\n","    print(f\"  Precision: {test_precision:.4f}\")\n","    print(f\"  Recall:    {test_recall:.4f}\")\n","    print(f\"  F1-Score:  {f1_score:.4f}\")\n","    print(f\"  AUC:       {test_auc:.4f}\")\n","\n","    # Classification report\n","    print(f\"\\nğŸ“‹ Classification Report:\")\n","    print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=['NORMAL', 'PNEUMONIA'],\n","                yticklabels=['NORMAL', 'PNEUMONIA'])\n","    plt.title(f'Confusion Matrix - {model_name}')\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    plt.savefig(os.path.join(DRIVE_PATH, f'{model_name}_confusion_matrix.png'))\n","    plt.close()\n","\n","    # ROC curve\n","    fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {test_auc:.3f})', linewidth=2)\n","    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve - {model_name}')\n","    plt.legend()\n","    plt.grid(alpha=0.3)\n","    plt.savefig(os.path.join(DRIVE_PATH, f'{model_name}_roc_curve.png'))\n","    plt.close()\n","\n","    return {\n","        'accuracy': test_acc,\n","        'precision': test_precision,\n","        'recall': test_recall,\n","        'f1_score': f1_score,\n","        'auc': test_auc\n","    }"],"metadata":{"id":"9sDdClFHcIxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    \"\"\"\n","    Generate Grad-CAM heatmap for model interpretability\n","    \"\"\"\n","    # Create a model that maps input to last conv layer and output\n","    grad_model = Model(\n","        inputs=[model.inputs],\n","        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Compute gradient\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(predictions[0])\n","        class_channel = predictions[:, pred_index]\n","\n","    # Gradient of output with respect to conv layer\n","    grads = tape.gradient(class_channel, conv_outputs)\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    conv_outputs = conv_outputs[0]\n","    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","\n","    return heatmap.numpy()"],"metadata":{"id":"zIhGHeR0cgvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_gradcam(img_path, model, model_name, last_conv_layer_name):\n","    \"\"\"\n","    Visualize Grad-CAM on an X-ray image\n","    \"\"\"\n","    # Load and preprocess image\n","    img = keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n","    img_array = keras.preprocessing.image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","\n","    # Get prediction\n","    pred = model.predict(img_array, verbose=0)[0][0]\n","    pred_class = \"PNEUMONIA\" if pred > 0.5 else \"NORMAL\"\n","\n","    # Generate heatmap\n","    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","\n","    # Superimpose heatmap on image\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n","    heatmap = np.uint8(255 * heatmap)\n","    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","    superimposed = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n","\n","    # Plot\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","    axes[0].set_title('Original X-Ray')\n","    axes[0].axis('off')\n","\n","    axes[1].imshow(heatmap)\n","    axes[1].set_title('Grad-CAM Heatmap')\n","    axes[1].axis('off')\n","\n","    axes[2].imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n","    axes[2].set_title(f'Overlay\\nPrediction: {pred_class} ({pred:.2f})')\n","    axes[2].axis('off')\n","\n","    plt.suptitle(f'{model_name} - Grad-CAM Visualization', fontsize=14, fontweight='bold')\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(DRIVE_PATH, f'{model_name}_gradcam.png'))\n","    print(f\"âœ… Grad-CAM saved to Drive: {DRIVE_PATH}{model_name}_gradcam.png\")\n","    plt.close()\n","\n","    print(f\"âœ… Grad-CAM saved: {model_name}_gradcam.png\")\n","    return pred, pred_class\n"],"metadata":{"id":"CvJSqeKEd69q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ensemble_predict(models_dict, img_path):\n","    \"\"\"\n","    Ensemble prediction using all models\n","    \"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(\"ENSEMBLE PREDICTION\")\n","    print(f\"{'='*60}\")\n","\n","    # Load and preprocess\n","    img = keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n","    img_array = keras.preprocessing.image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","\n","    predictions = {}\n","    for name, model in models_dict.items():\n","        pred = model.predict(img_array, verbose=0)[0][0]\n","        pred_class = \"PNEUMONIA\" if pred > 0.5 else \"NORMAL\"\n","        predictions[name] = pred\n","        print(f\"  {name:20s}: {pred:.4f} ({pred_class})\")\n","\n","    # Ensemble (average)\n","    ensemble_pred = np.mean(list(predictions.values()))\n","    ensemble_class = \"PNEUMONIA\" if ensemble_pred > 0.5 else \"NORMAL\"\n","    confidence = ensemble_pred * 100 if ensemble_pred > 0.5 else (1 - ensemble_pred) * 100\n","\n","    print(f\"\\nğŸ”® Ensemble Result: {ensemble_class}\")\n","    print(f\"   Confidence: {confidence:.2f}%\")\n","\n","    return predictions, ensemble_pred, ensemble_class, confidence\n"],"metadata":{"id":"TUxsUvclenZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    # Define models to train\n","    models_config = [\n","        (DenseNet121, \"DenseNet121\", \"conv5_block16_concat\"),\n","        (ResNet50, \"ResNet50\", \"conv5_block3_out\"),\n","        (EfficientNetB0, \"EfficientNetB0\", \"top_activation\")\n","    ]\n","\n","    trained_models = {}\n","    all_results = {}\n","\n","    # Train each model\n","    for base_builder, name, last_conv_layer in models_config:\n","        print(f\"\\n\\n{'#'*60}\")\n","        print(f\"# PROCESSING: {name}\")\n","        print(f\"{'#'*60}\\n\")\n","\n","        # Build model\n","        model, base_model = build_model(base_builder, name)\n","        print(f\"âœ… Model built: {name}\")\n","        print(f\"Total parameters: {model.count_params():,}\")\n","\n","        # Train\n","        hist1, hist2 = train_model(model, base_model, name)\n","\n","        # Evaluate\n","        results = evaluate_model(model, name, test_generator)\n","        all_results[name] = results\n","\n","        # Save trained model\n","        trained_models[name] = model\n","        model.save(os.path.join(DRIVE_PATH, f'{name}_final.h5'))\n","        print(f\"âœ… Final model saved to Drive: {DRIVE_PATH}{name}_final.h5\")\n","\n","\n","    # ========== FINAL COMPARISON ==========\n","    print(f\"\\n\\n{'='*60}\")\n","    print(\"FINAL MODEL COMPARISON\")\n","    print(f\"{'='*60}\\n\")\n","\n","    import pandas as pd\n","    results_df = pd.DataFrame(all_results).T\n","    print(results_df.to_string())\n","\n","    best_model = results_df['f1_score'].idxmax()\n","    print(f\"\\nğŸ† Best Model: {best_model}\")\n","    print(f\"   F1-Score: {results_df.loc[best_model, 'f1_score']:.4f}\")\n","    print(f\"   AUC: {results_df.loc[best_model, 'auc']:.4f}\")\n","\n","    # ========== DEMO: SINGLE PREDICTION WITH ENSEMBLE ==========\n","    print(f\"\\n\\n{'='*60}\")\n","    print(\"DEMO: PREDICTION PIPELINE\")\n","    print(f\"{'='*60}\")\n","\n","    # Get a sample test image\n","    import os\n","    test_pneumonia_dir = os.path.join(TEST_DIR, 'PNEUMONIA')\n","    sample_images = os.listdir(test_pneumonia_dir)[:1]\n","\n","    if sample_images:\n","        sample_path = os.path.join(test_pneumonia_dir, sample_images[0])\n","\n","        # Ensemble prediction\n","        preds, ens_pred, ens_class, conf = ensemble_predict(trained_models, sample_path)\n","        print(f\"\\nGenerating Grad-CAM for {best_model}...\")\n","        best_conv_layer = [layer for _, name, layer in models_config if name == best_model][0]\n","        visualize_gradcam(sample_path, trained_models[best_model], best_model, best_conv_layer)\n","print(f\"\\n{'='*60}\")\n","print(\"âœ… PIPELINE COMPLETE!\")\n","print(f\"{'='*60}\")\n","print(\"\\nAll models trained, evaluated, and saved.\")\n","print(\"Check the generated plots and saved models in the current directory.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Qp7So-1sfM_6","executionInfo":{"status":"error","timestamp":1768082483378,"user_tz":-300,"elapsed":6507631,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"f11996b8-22f1-47c0-fc8f-cf4903858870"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","############################################################\n","# PROCESSING: DenseNet121\n","############################################################\n","\n","âœ… Model built: DenseNet121\n","Total parameters: 7,337,025\n","\n","============================================================\n","TRAINING: DenseNet121\n","============================================================\n","\n","ğŸ”¹ STAGE 1: Feature Extraction (base frozen)\n","Base model trainable: False\n","Epoch 1/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8204 - auc: 0.9018 - loss: 0.3719 - precision: 0.9405 - recall: 0.8065\n","Epoch 1: val_auc improved from -inf to 1.00000, saving model to DenseNet121_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - accuracy: 0.8211 - auc: 0.9024 - loss: 0.3708 - precision: 0.9408 - recall: 0.8073 - val_accuracy: 0.8750 - val_auc: 1.0000 - val_loss: 0.2667 - val_precision: 1.0000 - val_recall: 0.7500 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9198 - auc: 0.9771 - loss: 0.1919 - precision: 0.9798 - recall: 0.9110\n","Epoch 2: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9198 - auc: 0.9771 - loss: 0.1917 - precision: 0.9798 - recall: 0.9111 - val_accuracy: 0.9375 - val_auc: 0.9688 - val_loss: 0.2659 - val_precision: 1.0000 - val_recall: 0.8750 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9412 - auc: 0.9844 - loss: 0.1548 - precision: 0.9802 - recall: 0.9398\n","Epoch 3: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9412 - auc: 0.9844 - loss: 0.1548 - precision: 0.9802 - recall: 0.9398 - val_accuracy: 0.8125 - val_auc: 0.9453 - val_loss: 0.3105 - val_precision: 0.7273 - val_recall: 1.0000 - learning_rate: 0.0010\n","Epoch 4/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9479 - auc: 0.9846 - loss: 0.1495 - precision: 0.9844 - recall: 0.9447\n","Epoch 4: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9479 - auc: 0.9846 - loss: 0.1495 - precision: 0.9844 - recall: 0.9446 - val_accuracy: 0.8750 - val_auc: 0.9531 - val_loss: 0.2722 - val_precision: 1.0000 - val_recall: 0.7500 - learning_rate: 0.0010\n","Epoch 5/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9473 - auc: 0.9853 - loss: 0.1404 - precision: 0.9898 - recall: 0.9390\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 5: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.9473 - auc: 0.9853 - loss: 0.1403 - precision: 0.9897 - recall: 0.9390 - val_accuracy: 0.8750 - val_auc: 0.9531 - val_loss: 0.2809 - val_precision: 1.0000 - val_recall: 0.7500 - learning_rate: 0.0010\n","Epoch 6/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9483 - auc: 0.9871 - loss: 0.1302 - precision: 0.9892 - recall: 0.9411\n","Epoch 6: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9482 - auc: 0.9872 - loss: 0.1302 - precision: 0.9892 - recall: 0.9411 - val_accuracy: 0.8125 - val_auc: 0.9531 - val_loss: 0.2828 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n","Epoch 7/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9525 - auc: 0.9896 - loss: 0.1225 - precision: 0.9860 - recall: 0.9493\n","Epoch 7: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.9524 - auc: 0.9895 - loss: 0.1226 - precision: 0.9860 - recall: 0.9493 - val_accuracy: 0.8750 - val_auc: 0.9531 - val_loss: 0.2577 - val_precision: 0.8750 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n","Epoch 8/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9523 - auc: 0.9910 - loss: 0.1098 - precision: 0.9898 - recall: 0.9453\n","Epoch 8: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9523 - auc: 0.9910 - loss: 0.1099 - precision: 0.9898 - recall: 0.9454 - val_accuracy: 0.7500 - val_auc: 0.9375 - val_loss: 0.3044 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 5.0000e-04\n","Epoch 9/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9573 - auc: 0.9913 - loss: 0.1115 - precision: 0.9863 - recall: 0.9554\n","Epoch 9: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9573 - auc: 0.9913 - loss: 0.1115 - precision: 0.9863 - recall: 0.9554 - val_accuracy: 0.8125 - val_auc: 0.9375 - val_loss: 0.2776 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n","Epoch 10/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9509 - auc: 0.9900 - loss: 0.1166 - precision: 0.9861 - recall: 0.9481\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 10: val_auc did not improve from 1.00000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.9509 - auc: 0.9900 - loss: 0.1165 - precision: 0.9861 - recall: 0.9480 - val_accuracy: 0.8125 - val_auc: 0.9688 - val_loss: 0.3082 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n","Restoring model weights from the end of the best epoch: 7.\n","\n","ğŸ”¹ STAGE 2: Fine-Tuning (unfreeze top layers)\n","Total layers: 427\n","Trainable layers: 50\n","Epoch 1/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9444 - auc: 0.9853 - loss: 0.1510 - precision: 0.9783 - recall: 0.9458\n","Epoch 1: val_auc improved from -inf to 0.93750, saving model to DenseNet121_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.9444 - auc: 0.9853 - loss: 0.1508 - precision: 0.9784 - recall: 0.9458 - val_accuracy: 0.7500 - val_auc: 0.9375 - val_loss: 0.2987 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 1.0000e-05\n","Epoch 2/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9424 - auc: 0.9876 - loss: 0.1369 - precision: 0.9838 - recall: 0.9387\n","Epoch 2: val_auc did not improve from 0.93750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9425 - auc: 0.9876 - loss: 0.1369 - precision: 0.9839 - recall: 0.9387 - val_accuracy: 0.7500 - val_auc: 0.9375 - val_loss: 0.3207 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 1.0000e-05\n","Epoch 3/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9457 - auc: 0.9880 - loss: 0.1332 - precision: 0.9835 - recall: 0.9429\n","Epoch 3: val_auc did not improve from 0.93750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9457 - auc: 0.9880 - loss: 0.1331 - precision: 0.9835 - recall: 0.9430 - val_accuracy: 0.8125 - val_auc: 0.9375 - val_loss: 0.3113 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 1.0000e-05\n","Epoch 4/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9434 - auc: 0.9895 - loss: 0.1202 - precision: 0.9881 - recall: 0.9359\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\n","Epoch 4: val_auc did not improve from 0.93750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.9435 - auc: 0.9895 - loss: 0.1202 - precision: 0.9881 - recall: 0.9359 - val_accuracy: 0.8125 - val_auc: 0.9375 - val_loss: 0.3193 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 1.0000e-05\n","Epoch 5/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9552 - auc: 0.9927 - loss: 0.1018 - precision: 0.9912 - recall: 0.9476\n","Epoch 5: val_auc did not improve from 0.93750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9552 - auc: 0.9927 - loss: 0.1018 - precision: 0.9912 - recall: 0.9476 - val_accuracy: 0.8125 - val_auc: 0.9375 - val_loss: 0.3163 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-06\n","Epoch 6/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9493 - auc: 0.9900 - loss: 0.1241 - precision: 0.9837 - recall: 0.9475\n","Epoch 6: val_auc improved from 0.93750 to 0.96875, saving model to DenseNet121_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9493 - auc: 0.9900 - loss: 0.1241 - precision: 0.9838 - recall: 0.9475 - val_accuracy: 0.8125 - val_auc: 0.9688 - val_loss: 0.3139 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-06\n","Epoch 7/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9484 - auc: 0.9890 - loss: 0.1248 - precision: 0.9833 - recall: 0.9473\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\n","Epoch 7: val_auc did not improve from 0.96875\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9484 - auc: 0.9890 - loss: 0.1247 - precision: 0.9833 - recall: 0.9473 - val_accuracy: 0.8125 - val_auc: 0.9531 - val_loss: 0.3153 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 5.0000e-06\n","Epoch 8/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9561 - auc: 0.9926 - loss: 0.1032 - precision: 0.9903 - recall: 0.9497\n","Epoch 8: val_auc did not improve from 0.96875\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9561 - auc: 0.9925 - loss: 0.1034 - precision: 0.9903 - recall: 0.9496 - val_accuracy: 0.8125 - val_auc: 0.9609 - val_loss: 0.3135 - val_precision: 0.7778 - val_recall: 0.8750 - learning_rate: 2.5000e-06\n","Epoch 8: early stopping\n","Restoring model weights from the end of the best epoch: 1.\n","\n","âœ… DenseNet121 training completed!\n","\n","============================================================\n","EVALUATION: DenseNet121\n","============================================================\n","\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step\n","\n","ğŸ“Š Test Metrics:\n","  Accuracy:  0.8910\n","  Precision: 0.9328\n","  Recall:    0.8897\n","  F1-Score:  0.9108\n","  AUC:       0.9635\n","\n","ğŸ“‹ Classification Report:\n","              precision    recall  f1-score   support\n","\n","      NORMAL       0.83      0.89      0.86       234\n","   PNEUMONIA       0.93      0.89      0.91       390\n","\n","    accuracy                           0.89       624\n","   macro avg       0.88      0.89      0.89       624\n","weighted avg       0.89      0.89      0.89       624\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["âœ… Model saved: DenseNet121_final.h5\n","\n","\n","############################################################\n","# PROCESSING: ResNet50\n","############################################################\n","\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","âœ… Model built: ResNet50\n","Total parameters: 24,153,473\n","\n","============================================================\n","TRAINING: ResNet50\n","============================================================\n","\n","ğŸ”¹ STAGE 1: Feature Extraction (base frozen)\n","Base model trainable: False\n","Epoch 1/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7680 - auc: 0.8647 - loss: 0.4417 - precision: 0.9338 - recall: 0.7423\n","Epoch 1: val_auc improved from -inf to 0.78125, saving model to ResNet50_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.7685 - auc: 0.8651 - loss: 0.4411 - precision: 0.9339 - recall: 0.7428 - val_accuracy: 0.5000 - val_auc: 0.7812 - val_loss: 0.6742 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8434 - auc: 0.9229 - loss: 0.3511 - precision: 0.9545 - recall: 0.8287\n","Epoch 2: val_auc improved from 0.78125 to 0.78906, saving model to ResNet50_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8435 - auc: 0.9229 - loss: 0.3508 - precision: 0.9546 - recall: 0.8287 - val_accuracy: 0.6250 - val_auc: 0.7891 - val_loss: 0.6631 - val_precision: 0.5714 - val_recall: 1.0000 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8483 - auc: 0.9312 - loss: 0.3137 - precision: 0.9707 - recall: 0.8237\n","Epoch 3: val_auc did not improve from 0.78906\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8484 - auc: 0.9313 - loss: 0.3137 - precision: 0.9707 - recall: 0.8238 - val_accuracy: 0.6875 - val_auc: 0.7422 - val_loss: 0.6509 - val_precision: 0.6364 - val_recall: 0.8750 - learning_rate: 0.0010\n","Epoch 4/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8558 - auc: 0.9415 - loss: 0.2946 - precision: 0.9749 - recall: 0.8276\n","Epoch 4: val_auc did not improve from 0.78906\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8558 - auc: 0.9414 - loss: 0.2946 - precision: 0.9748 - recall: 0.8277 - val_accuracy: 0.6250 - val_auc: 0.7734 - val_loss: 0.6290 - val_precision: 0.5714 - val_recall: 1.0000 - learning_rate: 0.0010\n","Epoch 5/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8630 - auc: 0.9419 - loss: 0.2881 - precision: 0.9711 - recall: 0.8404\n","Epoch 5: val_auc did not improve from 0.78906\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8630 - auc: 0.9419 - loss: 0.2881 - precision: 0.9711 - recall: 0.8404 - val_accuracy: 0.6875 - val_auc: 0.7578 - val_loss: 0.6016 - val_precision: 0.6364 - val_recall: 0.8750 - learning_rate: 0.0010\n","Epoch 6/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8666 - auc: 0.9460 - loss: 0.2781 - precision: 0.9772 - recall: 0.8417\n","Epoch 6: val_auc did not improve from 0.78906\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8666 - auc: 0.9460 - loss: 0.2782 - precision: 0.9771 - recall: 0.8417 - val_accuracy: 0.6875 - val_auc: 0.7656 - val_loss: 0.6845 - val_precision: 0.6364 - val_recall: 0.8750 - learning_rate: 0.0010\n","Epoch 7/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8679 - auc: 0.9457 - loss: 0.2807 - precision: 0.9764 - recall: 0.8436\n","Epoch 7: val_auc improved from 0.78906 to 0.84375, saving model to ResNet50_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8679 - auc: 0.9457 - loss: 0.2808 - precision: 0.9763 - recall: 0.8436 - val_accuracy: 0.6875 - val_auc: 0.8438 - val_loss: 0.7638 - val_precision: 0.6154 - val_recall: 1.0000 - learning_rate: 0.0010\n","Epoch 8/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8737 - auc: 0.9483 - loss: 0.2753 - precision: 0.9756 - recall: 0.8522\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 8: val_auc did not improve from 0.84375\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8737 - auc: 0.9483 - loss: 0.2753 - precision: 0.9756 - recall: 0.8522 - val_accuracy: 0.6875 - val_auc: 0.7422 - val_loss: 0.8190 - val_precision: 0.6364 - val_recall: 0.8750 - learning_rate: 0.0010\n","Epoch 9/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8709 - auc: 0.9430 - loss: 0.2865 - precision: 0.9761 - recall: 0.8481\n","Epoch 9: val_auc did not improve from 0.84375\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.8710 - auc: 0.9430 - loss: 0.2863 - precision: 0.9761 - recall: 0.8482 - val_accuracy: 0.6875 - val_auc: 0.7500 - val_loss: 0.7478 - val_precision: 0.6364 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n","Epoch 10/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8698 - auc: 0.9515 - loss: 0.2655 - precision: 0.9734 - recall: 0.8494\n","Epoch 10: val_auc did not improve from 0.84375\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.8699 - auc: 0.9516 - loss: 0.2654 - precision: 0.9734 - recall: 0.8495 - val_accuracy: 0.7500 - val_auc: 0.7891 - val_loss: 0.7767 - val_precision: 0.6667 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n","Epoch 10: early stopping\n","Restoring model weights from the end of the best epoch: 5.\n","\n","ğŸ”¹ STAGE 2: Fine-Tuning (unfreeze top layers)\n","Total layers: 175\n","Trainable layers: 50\n","Epoch 1/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7899 - auc: 0.8622 - loss: 0.6653 - precision: 0.9317 - recall: 0.7759\n","Epoch 1: val_auc improved from -inf to 0.78125, saving model to ResNet50_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.7902 - auc: 0.8626 - loss: 0.6639 - precision: 0.9319 - recall: 0.7761 - val_accuracy: 0.6250 - val_auc: 0.7812 - val_loss: 0.9742 - val_precision: 0.5714 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 2/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8432 - auc: 0.9215 - loss: 0.3936 - precision: 0.9608 - recall: 0.8238\n","Epoch 2: val_auc did not improve from 0.78125\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8433 - auc: 0.9215 - loss: 0.3934 - precision: 0.9608 - recall: 0.8239 - val_accuracy: 0.5000 - val_auc: 0.5625 - val_loss: 4.3007 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 3/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8438 - auc: 0.9268 - loss: 0.3719 - precision: 0.9683 - recall: 0.8183\n","Epoch 3: val_auc improved from 0.78125 to 0.82031, saving model to ResNet50_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.8438 - auc: 0.9268 - loss: 0.3720 - precision: 0.9682 - recall: 0.8184 - val_accuracy: 0.5625 - val_auc: 0.8203 - val_loss: 2.0182 - val_precision: 0.5333 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 4/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8633 - auc: 0.9383 - loss: 0.3237 - precision: 0.9732 - recall: 0.8373\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\n","Epoch 4: val_auc improved from 0.82031 to 0.83594, saving model to ResNet50_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.8632 - auc: 0.9382 - loss: 0.3237 - precision: 0.9732 - recall: 0.8373 - val_accuracy: 0.5625 - val_auc: 0.8359 - val_loss: 1.5245 - val_precision: 0.5333 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 5/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8685 - auc: 0.9425 - loss: 0.2992 - precision: 0.9719 - recall: 0.8482\n","Epoch 5: val_auc improved from 0.83594 to 0.87500, saving model to ResNet50_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.8684 - auc: 0.9425 - loss: 0.2992 - precision: 0.9718 - recall: 0.8481 - val_accuracy: 0.7500 - val_auc: 0.8750 - val_loss: 0.5589 - val_precision: 0.7000 - val_recall: 0.8750 - learning_rate: 5.0000e-06\n","Epoch 6/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8678 - auc: 0.9428 - loss: 0.3164 - precision: 0.9724 - recall: 0.8468\n","Epoch 6: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.8678 - auc: 0.9428 - loss: 0.3164 - precision: 0.9724 - recall: 0.8468 - val_accuracy: 0.7500 - val_auc: 0.8125 - val_loss: 1.3416 - val_precision: 0.7000 - val_recall: 0.8750 - learning_rate: 5.0000e-06\n","Epoch 7/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8747 - auc: 0.9516 - loss: 0.2718 - precision: 0.9796 - recall: 0.8493\n","Epoch 7: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8746 - auc: 0.9516 - loss: 0.2719 - precision: 0.9796 - recall: 0.8493 - val_accuracy: 0.5625 - val_auc: 0.7734 - val_loss: 2.2401 - val_precision: 0.5333 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n","Epoch 8/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8771 - auc: 0.9473 - loss: 0.2791 - precision: 0.9749 - recall: 0.8563\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\n","Epoch 8: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8772 - auc: 0.9473 - loss: 0.2790 - precision: 0.9749 - recall: 0.8564 - val_accuracy: 0.7500 - val_auc: 0.8750 - val_loss: 0.6305 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 5.0000e-06\n","Epoch 9/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8849 - auc: 0.9544 - loss: 0.2635 - precision: 0.9771 - recall: 0.8656\n","Epoch 9: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8848 - auc: 0.9544 - loss: 0.2635 - precision: 0.9771 - recall: 0.8655 - val_accuracy: 0.6875 - val_auc: 0.7734 - val_loss: 2.1527 - val_precision: 0.6154 - val_recall: 1.0000 - learning_rate: 2.5000e-06\n","Epoch 10/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8782 - auc: 0.9533 - loss: 0.2789 - precision: 0.9731 - recall: 0.8612\n","Epoch 10: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8782 - auc: 0.9533 - loss: 0.2789 - precision: 0.9731 - recall: 0.8611 - val_accuracy: 0.7500 - val_auc: 0.8281 - val_loss: 0.6800 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 2.5000e-06\n","Epoch 11/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8852 - auc: 0.9578 - loss: 0.2497 - precision: 0.9775 - recall: 0.8659\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n","\n","Epoch 11: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8852 - auc: 0.9578 - loss: 0.2497 - precision: 0.9775 - recall: 0.8659 - val_accuracy: 0.6250 - val_auc: 0.7969 - val_loss: 0.9096 - val_precision: 0.7500 - val_recall: 0.3750 - learning_rate: 2.5000e-06\n","Epoch 12/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8902 - auc: 0.9603 - loss: 0.2393 - precision: 0.9755 - recall: 0.8747\n","Epoch 12: val_auc did not improve from 0.87500\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8902 - auc: 0.9603 - loss: 0.2393 - precision: 0.9755 - recall: 0.8746 - val_accuracy: 0.7500 - val_auc: 0.8047 - val_loss: 0.7441 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 1.2500e-06\n","Epoch 12: early stopping\n","Restoring model weights from the end of the best epoch: 5.\n","\n","âœ… ResNet50 training completed!\n","\n","============================================================\n","EVALUATION: ResNet50\n","============================================================\n","\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step\n","\n","ğŸ“Š Test Metrics:\n","  Accuracy:  0.8333\n","  Precision: 0.9040\n","  Recall:    0.8205\n","  F1-Score:  0.8602\n","  AUC:       0.8972\n","\n","ğŸ“‹ Classification Report:\n","              precision    recall  f1-score   support\n","\n","      NORMAL       0.74      0.85      0.79       234\n","   PNEUMONIA       0.90      0.82      0.86       390\n","\n","    accuracy                           0.83       624\n","   macro avg       0.82      0.84      0.83       624\n","weighted avg       0.84      0.83      0.84       624\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["âœ… Model saved: ResNet50_final.h5\n","\n","\n","############################################################\n","# PROCESSING: EfficientNetB0\n","############################################################\n","\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","âœ… Model built: EfficientNetB0\n","Total parameters: 4,415,652\n","\n","============================================================\n","TRAINING: EfficientNetB0\n","============================================================\n","\n","ğŸ”¹ STAGE 1: Feature Extraction (base frozen)\n","Base model trainable: False\n","Epoch 1/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5128 - auc: 0.5135 - loss: 0.8642 - precision: 0.7454 - recall: 0.5132\n","Epoch 1: val_auc improved from -inf to 0.43750, saving model to EfficientNetB0_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 2s/step - accuracy: 0.5128 - auc: 0.5134 - loss: 0.8640 - precision: 0.7454 - recall: 0.5132 - val_accuracy: 0.5000 - val_auc: 0.4375 - val_loss: 0.6938 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5083 - auc: 0.5017 - loss: 0.7746 - precision: 0.7367 - recall: 0.5211\n","Epoch 2: val_auc improved from 0.43750 to 0.50000, saving model to EfficientNetB0_feature_extraction.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.5083 - auc: 0.5018 - loss: 0.7744 - precision: 0.7368 - recall: 0.5210 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5059 - auc: 0.5187 - loss: 0.7495 - precision: 0.7447 - recall: 0.4985\n","Epoch 3: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.5060 - auc: 0.5186 - loss: 0.7494 - precision: 0.7447 - recall: 0.4988 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 4/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5125 - auc: 0.4992 - loss: 0.7209 - precision: 0.7431 - recall: 0.5278\n","Epoch 4: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.5125 - auc: 0.4992 - loss: 0.7209 - precision: 0.7431 - recall: 0.5277 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 5/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4916 - auc: 0.4908 - loss: 0.7161 - precision: 0.7337 - recall: 0.4959\n","Epoch 5: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.4915 - auc: 0.4907 - loss: 0.7161 - precision: 0.7337 - recall: 0.4957 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 6/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5019 - auc: 0.5100 - loss: 0.7098 - precision: 0.7404 - recall: 0.4998\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 6: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.5019 - auc: 0.5099 - loss: 0.7098 - precision: 0.7405 - recall: 0.5000 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n","Epoch 7/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5296 - auc: 0.4886 - loss: 0.7000 - precision: 0.7522 - recall: 0.5554\n","Epoch 7: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.5290 - auc: 0.4887 - loss: 0.7001 - precision: 0.7521 - recall: 0.5542 - val_accuracy: 0.5000 - val_auc: 0.4375 - val_loss: 0.6932 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n","Epoch 8/10\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4810 - auc: 0.5277 - loss: 0.7008 - precision: 0.7529 - recall: 0.4412\n","Epoch 8: val_auc did not improve from 0.50000\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.4811 - auc: 0.5277 - loss: 0.7007 - precision: 0.7529 - recall: 0.4414 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n","Epoch 8: early stopping\n","Restoring model weights from the end of the best epoch: 3.\n","\n","ğŸ”¹ STAGE 2: Fine-Tuning (unfreeze top layers)\n","Total layers: 238\n","Trainable layers: 50\n","Epoch 1/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4850 - auc: 0.4990 - loss: 0.7185 - precision: 0.7379 - recall: 0.4739\n","Epoch 1: val_auc improved from -inf to 0.68750, saving model to EfficientNetB0_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.4850 - auc: 0.4990 - loss: 0.7184 - precision: 0.7379 - recall: 0.4739 - val_accuracy: 0.5000 - val_auc: 0.6875 - val_loss: 0.6933 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 2/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4956 - auc: 0.4976 - loss: 0.7141 - precision: 0.7438 - recall: 0.4924\n","Epoch 2: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.4957 - auc: 0.4975 - loss: 0.7141 - precision: 0.7437 - recall: 0.4927 - val_accuracy: 0.5000 - val_auc: 0.3750 - val_loss: 0.6938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n","Epoch 3/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5186 - auc: 0.5155 - loss: 0.7111 - precision: 0.7506 - recall: 0.5288\n","Epoch 3: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.5185 - auc: 0.5154 - loss: 0.7112 - precision: 0.7505 - recall: 0.5288 - val_accuracy: 0.5000 - val_auc: 0.5625 - val_loss: 0.6933 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 4/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5298 - auc: 0.5179 - loss: 0.7014 - precision: 0.7610 - recall: 0.5431\n","Epoch 4: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.5297 - auc: 0.5179 - loss: 0.7014 - precision: 0.7609 - recall: 0.5428 - val_accuracy: 0.5000 - val_auc: 0.5625 - val_loss: 0.6927 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 5/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5117 - auc: 0.5208 - loss: 0.6996 - precision: 0.7652 - recall: 0.5065\n","Epoch 5: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.5117 - auc: 0.5209 - loss: 0.6996 - precision: 0.7650 - recall: 0.5067 - val_accuracy: 0.5000 - val_auc: 0.5625 - val_loss: 0.6939 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 6/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4816 - auc: 0.5113 - loss: 0.7039 - precision: 0.7493 - recall: 0.4616\n","Epoch 6: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.4818 - auc: 0.5114 - loss: 0.7040 - precision: 0.7493 - recall: 0.4620 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6949 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 7/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5156 - auc: 0.5115 - loss: 0.7159 - precision: 0.7438 - recall: 0.5207\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\n","Epoch 7: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.5157 - auc: 0.5115 - loss: 0.7158 - precision: 0.7439 - recall: 0.5207 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6940 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n","Epoch 8/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4993 - auc: 0.5131 - loss: 0.7099 - precision: 0.7473 - recall: 0.4883\n","Epoch 8: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.4995 - auc: 0.5132 - loss: 0.7099 - precision: 0.7474 - recall: 0.4885 - val_accuracy: 0.5000 - val_auc: 0.6875 - val_loss: 0.6936 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n","Epoch 9/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5333 - auc: 0.5468 - loss: 0.6991 - precision: 0.7725 - recall: 0.5253\n","Epoch 9: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.5332 - auc: 0.5466 - loss: 0.6992 - precision: 0.7724 - recall: 0.5253 - val_accuracy: 0.5000 - val_auc: 0.5625 - val_loss: 0.6932 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n","Epoch 10/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5181 - auc: 0.5379 - loss: 0.7032 - precision: 0.7480 - recall: 0.5198\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\n","Epoch 10: val_auc did not improve from 0.68750\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.5181 - auc: 0.5379 - loss: 0.7031 - precision: 0.7482 - recall: 0.5198 - val_accuracy: 0.5000 - val_auc: 0.6406 - val_loss: 0.6937 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n","Epoch 11/15\n","\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5130 - auc: 0.5105 - loss: 0.7030 - precision: 0.7580 - recall: 0.5122\n","Epoch 11: val_auc improved from 0.68750 to 0.72656, saving model to EfficientNetB0_fine_tuned.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.5131 - auc: 0.5106 - loss: 0.7030 - precision: 0.7580 - recall: 0.5122 - val_accuracy: 0.5000 - val_auc: 0.7266 - val_loss: 0.6935 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-06\n","Epoch 11: early stopping\n","Restoring model weights from the end of the best epoch: 4.\n","\n","âœ… EfficientNetB0 training completed!\n","\n","============================================================\n","EVALUATION: EfficientNetB0\n","============================================================\n","\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step\n","\n","ğŸ“Š Test Metrics:\n","  Accuracy:  0.6250\n","  Precision: 0.6250\n","  Recall:    1.0000\n","  F1-Score:  0.7692\n","  AUC:       0.5457\n","\n","ğŸ“‹ Classification Report:\n","              precision    recall  f1-score   support\n","\n","      NORMAL       0.00      0.00      0.00       234\n","   PNEUMONIA       0.62      1.00      0.77       390\n","\n","    accuracy                           0.62       624\n","   macro avg       0.31      0.50      0.38       624\n","weighted avg       0.39      0.62      0.48       624\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["âœ… Model saved: EfficientNetB0_final.h5\n","\n","\n","============================================================\n","FINAL MODEL COMPARISON\n","============================================================\n","\n","                accuracy  precision    recall  f1_score       auc\n","DenseNet121     0.891026   0.932796  0.889744  0.910761  0.963533\n","ResNet50        0.833333   0.903955  0.820513  0.860215  0.897184\n","EfficientNetB0  0.625000   0.625000  1.000000  0.769231  0.545726\n","\n","ğŸ† Best Model: DenseNet121\n","   F1-Score: 0.9108\n","   AUC: 0.9635\n","\n","\n","============================================================\n","DEMO: PREDICTION PIPELINE\n","============================================================\n","\n","============================================================\n","ENSEMBLE PREDICTION\n","============================================================\n","  DenseNet121         : 0.9291 (PNEUMONIA)\n","  ResNet50            : 0.9405 (PNEUMONIA)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d5f16348220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["  EfficientNetB0      : 0.5247 (PNEUMONIA)\n","\n","ğŸ”® Ensemble Result: PNEUMONIA\n","   Confidence: 79.81%\n","\n","Generating Grad-CAM for DenseNet121...\n"]},{"output_type":"error","ename":"ValueError","evalue":"No such layer: conv5_block16_concat. Existing layers are: ['input_layer_3', 'densenet121', 'global_average_pooling2d_1', 'batch_normalization_1', 'dense_3', 'dropout_2', 'dense_4', 'dropout_3', 'dense_5'].","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2536241627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nGenerating Grad-CAM for {best_model}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mbest_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_config\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mvisualize_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_conv_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{'='*60}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… PIPELINE COMPLETE!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-813406563.py\u001b[0m in \u001b[0;36mvisualize_gradcam\u001b[0;34m(img_path, model, model_name, last_conv_layer_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Generate heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_gradcam_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Superimpose heatmap on image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4177663786.py\u001b[0m in \u001b[0;36mmake_gradcam_heatmap\u001b[0;34m(img_array, model, last_conv_layer_name, pred_index)\u001b[0m\n\u001b[1;32m      6\u001b[0m     grad_model = Model(\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_conv_layer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No such layer: conv5_block16_concat. Existing layers are: ['input_layer_3', 'densenet121', 'global_average_pooling2d_1', 'batch_normalization_1', 'dense_3', 'dropout_2', 'dense_4', 'dropout_3', 'dense_5']."]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"YULXrAsjiRYV","executionInfo":{"status":"ok","timestamp":1768125039914,"user_tz":-300,"elapsed":21545,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a845a47c-6958-4949-9dff-8586dabce837"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Simple Ensemble Prediction - No Training, No LLM\n","Just load models and predict\n","\"\"\"\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","import os\n","\n","# ============================================================\n","# STEP 1: LOAD YOUR TRAINED MODELS\n","# ============================================================\n","print(\"=\"*60)\n","print(\"Loading Models...\")\n","print(\"=\"*60)\n","\n","# Model files (adjust names if different)\n","model_files = {\n","    'DenseNet121': '/content/drive/MyDrive/Colab Notebooks/medicalimagefiles/DenseNet121_final.h5',\n","    'ResNet50': '/content/drive/MyDrive/Colab Notebooks/medicalimagefiles/ResNet50_final.h5',\n","    'EfficientNetB0': '/content/drive/MyDrive/Colab Notebooks/medicalimagefiles/EfficientNetB0_final.h5'\n","}\n","\n","models = {}\n","for name, path in model_files.items():\n","    if os.path.exists(path):\n","        print(f\"Loading {name}...\")\n","        models[name] = keras.models.load_model(path)\n","        print(f\"  âœ… {name} loaded!\")\n","    else:\n","        print(f\"  âŒ {path} not found!\")\n","\n","print(f\"\\nâœ… {len(models)} models loaded successfully!\\n\")\n","\n","# ============================================================\n","# STEP 2: ENSEMBLE PREDICTION FUNCTION\n","# ============================================================\n","def ensemble_predict(image_path, models_dict):\n","    \"\"\"\n","    Predict using ensemble of models\n","    \"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Predicting: {image_path}\")\n","    print(f\"{'='*60}\\n\")\n","\n","    # Load and preprocess image\n","    img = image.load_img(image_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","\n","    # Get predictions from each model\n","    predictions = {}\n","    print(\"Individual Predictions:\")\n","    print(\"-\" * 60)\n","\n","    for model_name, model in models_dict.items():\n","        pred = model.predict(img_array, verbose=0)[0][0]\n","        result = \"PNEUMONIA\" if pred > 0.5 else \"NORMAL\"\n","        confidence = pred * 100 if pred > 0.5 else (1 - pred) * 100\n","\n","        predictions[model_name] = pred\n","        print(f\"  {model_name:20s}: {pred:.4f} â†’ {result:10s} ({confidence:.2f}%)\")\n","\n","    # Calculate ensemble (average of all models)\n","    ensemble_score = np.mean(list(predictions.values()))\n","    ensemble_result = \"PNEUMONIA\" if ensemble_score > 0.5 else \"NORMAL\"\n","    ensemble_confidence = ensemble_score * 100 if ensemble_score > 0.5 else (1 - ensemble_score) * 100\n","\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"ENSEMBLE RESULT:\")\n","    print(\"=\" * 60)\n","    print(f\"  Prediction: {ensemble_result}\")\n","    print(f\"  Confidence: {ensemble_confidence:.2f}%\")\n","    print(f\"  Score: {ensemble_score:.4f}\")\n","    print(\"=\" * 60)\n","\n","    return predictions, ensemble_result, ensemble_confidence\n","\n","# ============================================================\n","# STEP 3: TEST IT!\n","# ============================================================\n","\n","# Change this to your test image path\n","test_image = \"/content/chest_xray/test/PNEUMONIA/person114_bacteria_546.jpeg\"\n","\n","# Or try multiple images\n","# test_images = [\n","#     \"chest_xray/test/PNEUMONIA/person1_virus_6.jpeg\",\n","#     \"chest_xray/test/NORMAL/IM-0001-0001.jpeg\",\n","# ]\n","\n","if os.path.exists(test_image):\n","    predictions, result, confidence = ensemble_predict(test_image, models)\n","else:\n","    print(f\"âŒ Image not found: {test_image}\")\n","    print(\"\\nğŸ’¡ To use:\")\n","    print(\"  1. Change 'test_image' variable to your X-ray path\")\n","    print(\"  2. Or run: ensemble_predict('your_image.jpg', models)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gohRw-PUWt47","executionInfo":{"status":"ok","timestamp":1768125642684,"user_tz":-300,"elapsed":12220,"user":{"displayName":"Ayanali","userId":"07482133169682411462"}},"outputId":"140809f9-43e5-40c4-ead4-9e39b362e711"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Loading Models...\n","============================================================\n","Loading DenseNet121...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["  âœ… DenseNet121 loaded!\n","Loading ResNet50...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["  âœ… ResNet50 loaded!\n","Loading EfficientNetB0...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["  âœ… EfficientNetB0 loaded!\n","\n","âœ… 3 models loaded successfully!\n","\n","\n","============================================================\n","Predicting: /content/chest_xray/test/PNEUMONIA/person114_bacteria_546.jpeg\n","============================================================\n","\n","Individual Predictions:\n","------------------------------------------------------------\n","  DenseNet121         : 1.0000 â†’ PNEUMONIA  (100.00%)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb72af14400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["  ResNet50            : 0.9695 â†’ PNEUMONIA  (96.95%)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb72af14680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["  EfficientNetB0      : 0.5047 â†’ PNEUMONIA  (50.47%)\n","\n","============================================================\n","ENSEMBLE RESULT:\n","============================================================\n","  Prediction: PNEUMONIA\n","  Confidence: 82.47%\n","  Score: 0.8247\n","============================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"shIP-AbteEOc"},"execution_count":null,"outputs":[]}]}